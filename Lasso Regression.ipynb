{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "## Digital Advertising 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### must download csv from this link https://www.dropbox.com/s/5oims4fko6uo5px/finalmaster-ratios.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "import matplotlib.pyplot as plt\n",
    "#impor the data set as a pandas dataframe\n",
    "alldata=pd.read_csv('finalmaster-ratios.csv')\n",
    "\n",
    "#get column header names\n",
    "allvariablenames=list(alldata.columns.values)\n",
    "\n",
    "#remove first 8 column headers\n",
    "listofallpredictors=allvariablenames[8:]\n",
    "\n",
    "#load predictors into dataframe\n",
    "predictors = alldata[listofallpredictors]  \n",
    "\n",
    "#load target into dataframe\n",
    "target=alldata['# Purchases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.739e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.736e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 9.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=5.579e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.483e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.383e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 24 iterations, alpha=5.383e-01, previous alpha=5.383e-01, with an active set of 17 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=4.457e-02, with an active set of 87 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=4.392e-02, with an active set of 89 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=3.408e-02, with an active set of 95 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.022e-02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 132 iterations, i.e. alpha=3.022e-02, with an active set of 100 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 134 iterations, alpha=3.001e-02, previous alpha=2.940e-02, with an active set of 101 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.200e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 8.689e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.188e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=7.036e-01, previous alpha=6.809e-01, with an active set of 18 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.916e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.645e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.456e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 6.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=1.867e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01001036' 2.7861365955132507]\n",
      "['B01001037' 0.9200572652790069]\n",
      "['B01001038' 0.9459340522644333]\n",
      "['B02001005' 0.39156809216155525]\n",
      "['B13014026' 0.22056164158451835]\n",
      "['B13014027' 0.05049787197081092]\n",
      "['B19001017' 1.6062678580473928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.734e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.709e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=1.692e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 6.580e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.668e-01, previous alpha=1.607e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 6.747e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.932e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.737e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.702e-01, previous alpha=1.687e-01, with an active set of 45 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.409e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.368e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.031e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.535e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=7.535e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.298e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.144e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 11 iterations, alpha=7.357e-01, previous alpha=6.074e-01, with an active set of 10 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.149e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.744e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.728e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.909e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=5.653e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 104 iterations, alpha=5.719e-02, previous alpha=5.400e-02, with an active set of 81 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=6.554e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.277e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=2.089e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.880e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 43 iterations, alpha=1.742e-01, previous alpha=1.733e-01, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\annie\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123)                   \n",
    "\n",
    "\n",
    "#use lasso to create model\n",
    "model=LassoLarsCV(cv=10,precompute=False).fit(pred_train,tar_train)\n",
    "\n",
    "#build coefficent chart\n",
    "\n",
    "predictors_model=pd.DataFrame(listofallpredictors)\n",
    "predictors_model.columns = ['label']\n",
    "predictors_model['coeff'] = model.coef_\n",
    "\n",
    "for index, row in predictors_model.iterrows():\n",
    "    if row['coeff'] > 0:\n",
    "        print(row.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Question 1-------------------\n",
      "The first line of code is creating a data frame predictors model that consists\n",
      " of the listofallpredictors variable.The second line of code is giving a label \n",
      "to the columns called label. The third line of code is adding a \n",
      "column called coefficients that is taking the coefficients from the lasso model\n",
      "previously created. The next three lines are the for loop. These lines\n",
      "essentially loop through the data frame and prints any coefficient \n",
      "that is greater than 0.\n",
      "===================================================================\n",
      "------------------------------#Question 2-------------------------\n",
      "The following demographic areas are all in your market share:\n",
      "These are the groups of people who buy your product\n",
      "Females between 30-34,\n",
      "Females between 35 - 39 years,Females between 40 - 44 years, Race:Asian,\n",
      "Women who have not had a baby in the past 12 months who are unmaried, with a bachelors degree,\n",
      " Women who have not had a baby in the past 12 months, who are unmaried, with \n",
      "a gradute or professional degree , and \n",
      "Houseshold income from past 12 months, $200,000 +\n",
      "================================================================\n",
      "-------------------------------#Question 3---------------------\n",
      "The two highest census labels are B01001036 and B01001017. \n",
      "The tow highest correspond to females between 30-34 years who\n",
      "Have a household income above 200k\n",
      "==========================================================\n",
      "----------------------------------question 4---------------------\n",
      "training data MSE\n",
      "22528.486826258624\n",
      "test data MSE\n",
      "41578.280293705764\n",
      "--------------Answer to question 4-----------------------------\n",
      "No the two mean squared errors are not similar . Practically speaking\n",
      "since MSE measures the quality of an estimator and the closer to zero,\n",
      "the better the estimator. This would mean that model is  a better predictor\n",
      "of the training data than the test data.\n",
      "===============================================================\n",
      "--------------Question 5---------------------------------------------\n",
      "training data R-square\n",
      "0.22266652028942102\n",
      "test data R-square\n",
      "0.17529294561525344\n",
      "---------------------answer to question 5\n",
      "The census data is not a good predictor. When looking at the R^2 values\n",
      "they are very low. This would not be a good estimator of predicting sales\n",
      "you should be aiming to have R^2 value that is at least .7.\n",
      "This is not something you should be making decisions on when it will\n",
      "greatly affect your financial standing. If you have a .75 R^2 value or higher\n",
      "you have much more predictive power\n",
      "=================================================================\n",
      "-----------------------Question 6---------------------------------\n",
      "y interecept:\n",
      "2.758738710322305\n",
      "---------------------------------answer to question 6\n",
      "The baseline sales number is 2 bobo bars. This of course reflects\n",
      "the sales numbers without any other predictors(beta coefficient) taken\n",
      "into consideration. Essentially this number reflects how many bars\n",
      "sold if you had no market share\n",
      "===================================================================\n"
     ]
    }
   ],
   "source": [
    "print('--------------------------------------Question 1-------------------')\n",
    "print('The first line of code is creating a data frame predictors model that consists')\n",
    "print(' of the listofallpredictors variable.The second line of code is giving a label ')\n",
    "print ('to the columns called label. The third line of code is adding a ')\n",
    "print('column called coefficients that is taking the coefficients from the lasso model') \n",
    "print('previously created. The next three lines are the for loop. These lines')\n",
    "print('essentially loop through the data frame and prints any coefficient ')\n",
    "print('that is greater than 0.' )\n",
    "print ('===================================================================')\n",
    "print('------------------------------#Question 2-------------------------')\n",
    "\n",
    "print('The following demographic areas are all in your market share:')\n",
    "print ('These are the groups of people who buy your product')\n",
    "print('Females between 30-34,')\n",
    "print ('Females between 35 - 39 years,Females between 40 - 44 years, Race:Asian,' )\n",
    "print ('Women who have not had a baby in the past 12 months who are unmaried, with a bachelors degree,')\n",
    "print (' Women who have not had a baby in the past 12 months, who are unmaried, with ')\n",
    "print('a gradute or professional degree , and ')\n",
    "print('Houseshold income from past 12 months, $200,000 +')\n",
    "\n",
    "print ('================================================================')   \n",
    "print('-------------------------------#Question 3---------------------') \n",
    "print ('The two highest census labels are B01001036 and B01001017. ')\n",
    "print('The tow highest correspond to females between 30-34 years who')\n",
    "print ('Have a household income above 200k')\n",
    "print('==========================================================')\n",
    "print('----------------------------------question 4---------------------')\n",
    "#training data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
    "print ('training data MSE')\n",
    "print(train_error)\n",
    "test_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
    "print ('test data MSE')\n",
    "print(test_error)\n",
    "print('--------------Answer to question 4-----------------------------')\n",
    "print ('No the two mean squared errors are not similar . Practically speaking')\n",
    "print ('since MSE measures the quality of an estimator and the closer to zero,')\n",
    "print ('the better the estimator. This would mean that model is  a better predictor')\n",
    "print('of the training data than the test data.')\n",
    "print('===============================================================')\n",
    "\n",
    "print('--------------Question 5---------------------------------------------')\n",
    "#training data\n",
    "rsquared_train=model.score(pred_train,tar_train)\n",
    "print ('training data R-square')\n",
    "print(rsquared_train) \n",
    "#test data\n",
    "rsquared_test=model.score(pred_test,tar_test)\n",
    "print ('test data R-square')\n",
    "print(rsquared_test) \n",
    "print('---------------------answer to question 5')\n",
    "print ('The census data is not a good predictor. When looking at the R^2 values')\n",
    "print ('they are very low. This would not be a good estimator of predicting sales' )\n",
    "print ('you should be aiming to have R^2 value that is at least .7.')\n",
    "print ('This is not something you should be making decisions on when it will')\n",
    "print ('greatly affect your financial standing. If you have a .75 R^2 value or higher')\n",
    "print ('you have much more predictive power')\n",
    "print ('=================================================================')\n",
    "\n",
    "print ('-----------------------Question 6---------------------------------')\n",
    "print(\"y interecept:\")\n",
    "print(model.intercept_)\n",
    "print ('---------------------------------answer to question 6')\n",
    "print ('The baseline sales number is 2 bobo bars. This of course reflects')\n",
    "print ('the sales numbers without any other predictors(beta coefficient) taken')\n",
    "print ('into consideration. Essentially this number reflects how many bars')\n",
    "print ('sold if you had no market share')\n",
    "print ('===================================================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
